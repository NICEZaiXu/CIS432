import os
import pandas as pd
import numpy as np
import joblib
import streamlit as st
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, roc_auc_score

# =============================================================================
# æ¨¡å‹è®­ç»ƒéƒ¨åˆ†ï¼šè®­ç»ƒæ‰€æœ‰æ¨¡å‹å¹¶ä¿å­˜
# =============================================================================
def train_all_models():
    # è¯»å–æ•°æ®
    df = pd.read_csv("heloc_dataset_v1.csv")
    
    # å°†ç›®æ ‡å˜é‡è½¬æ¢ä¸ºæ•°å€¼ï¼šGood ä¸º 1ï¼ŒBad ä¸º 0
    df["RiskPerformance"] = df["RiskPerformance"].map({"Good": 1, "Bad": 0})
    
    # å°†ç‰¹æ®Šå€¼(-9, -8, -7)æ›¿æ¢ä¸º NaN
    special_values_list = [-9, -8, -7]
    df.replace(special_values_list, np.nan, inplace=True)
    
    # åˆ é™¤ç¼ºå¤±å€¼è¿‡å¤šçš„åˆ—ï¼ˆè¶…è¿‡ 40% çš„ç¼ºå¤±å€¼ï¼‰
    threshold = 0.4 * len(df)
    df_cleaned = df.dropna(thresh=threshold, axis=1)
    
    # å¯¹æ•°å€¼å‹ç‰¹å¾ç”¨ä¸­ä½æ•°å¡«å……ç¼ºå¤±å€¼
    for col in df_cleaned.columns:
        if df_cleaned[col].dtype in ["float64", "int64"]:
            df_cleaned[col].fillna(df_cleaned[col].median(), inplace=True)
    
    # ä½¿ç”¨ IQR æ–¹æ³•æ£€æµ‹å¼‚å¸¸å€¼ï¼Œå¹¶å°†è¶…å‡ºè¾¹ç•Œçš„å€¼æ›¿æ¢ä¸º NaNï¼Œå†ç”¨ä¸­ä½æ•°å¡«å……
    Q1 = df_cleaned.quantile(0.25)
    Q3 = df_cleaned.quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    for col in df_cleaned.columns:
        if df_cleaned[col].dtype in ["float64", "int64"]:
            df_cleaned[col] = np.where((df_cleaned[col] < lower_bound[col]) | (df_cleaned[col] > upper_bound[col]),
                                       np.nan, df_cleaned[col])
            df_cleaned[col].fillna(df_cleaned[col].median(), inplace=True)
    
    # åˆ†ç¦»ç‰¹å¾å’Œç›®æ ‡å˜é‡
    y = df_cleaned["RiskPerformance"]
    X = df_cleaned.drop(columns=["RiskPerformance"])
    
    # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼ˆ80% è®­ç»ƒï¼Œ20% æµ‹è¯•ï¼Œåˆ†å±‚æŠ½æ ·ï¼‰
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
    
    # å¯¹äº Logistic Regression å’Œ SVM ä½¿ç”¨æ ‡å‡†åŒ–æ•°æ®
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # å®šä¹‰æ‰€æœ‰æ¨¡å‹
    models = {
        "Logistic Regression": LogisticRegression(),
        "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
        "Decision Tree": DecisionTreeClassifier(random_state=42),
        "Gradient Boosting": GradientBoostingClassifier(n_estimators=100, random_state=42),
        "SVM": SVC(probability=True, random_state=42)
    }
    
    # è®­ç»ƒæ‰€æœ‰æ¨¡å‹å¹¶è¯„ä¼°ï¼ˆè¯„ä¼°ç»“æœä»…ä½œå‚è€ƒï¼‰
    for name, model in models.items():
        if name in ["Logistic Regression", "SVM"]:
            model.fit(X_train_scaled, y_train)
            y_pred = model.predict(X_test_scaled)
        else:
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        print(f"{name} Accuracy: {accuracy:.4f}")
    
    # ä¿å­˜æ‰€æœ‰æ¨¡å‹
    joblib.dump(models["Logistic Regression"], "logistic_regression.pkl")
    joblib.dump(models["Random Forest"], "random_forest.pkl")
    joblib.dump(models["Decision Tree"], "decision_tree.pkl")
    joblib.dump(models["Gradient Boosting"], "gradient_boosting.pkl")
    joblib.dump(models["SVM"], "svm.pkl")
    # åŒæ—¶ä¿å­˜ scalerï¼ˆç”¨äº Logistic Regression å’Œ SVMï¼‰
    joblib.dump(scaler, "scaler.pkl")
    print("æ‰€æœ‰æ¨¡å‹å’Œ scaler å·²ä¿å­˜ã€‚")

# å¦‚æœæ‰€æœ‰æ¨¡å‹æˆ– scaler æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ™è®­ç»ƒæ‰€æœ‰æ¨¡å‹
required_files = ["logistic_regression.pkl", "random_forest.pkl", "decision_tree.pkl", 
                  "gradient_boosting.pkl", "svm.pkl", "scaler.pkl"]
if not all(os.path.exists(f) for f in required_files):
    train_all_models()

# =============================================================================
# Streamlit éƒ¨ç½²éƒ¨åˆ†ï¼šä»…ä½¿ç”¨ Logistic Regression æ¨¡å‹è¿›è¡Œé¢„æµ‹åŠæ‹’ç»åŸå› åé¦ˆ
# =============================================================================

# åŠ è½½å·²ä¿å­˜çš„ Logistic Regression æ¨¡å‹å’Œ scaler
logistic_regression_model = joblib.load("logistic_regression.pkl")
scaler = joblib.load("scaler.pkl")

# å¤šè¯­è¨€ç¿»è¯‘å­—å…¸
translations = {
    "app_title": {
        "English": "ğŸ¦ Credit Risk Prediction App",
        "ä¸­æ–‡": "ğŸ¦ ä¿¡ç”¨é£é™©é¢„æµ‹åº”ç”¨",
        "í•œêµ­ì–´": "ğŸ¦ ì‹ ìš© ìœ„í—˜ ì˜ˆì¸¡ ì•±",
        "à¤¹à¤¿à¤‚à¤¦à¥€": "ğŸ¦ à¤•à¥à¤°à¥‡à¤¡à¤¿à¤Ÿ à¤œà¥‹à¤–à¤¿à¤® à¤­à¤µà¤¿à¤·à¥à¤¯à¤µà¤¾à¤£à¥€ à¤à¤ª"
    },
    "app_description": {
        "English": "Enter applicant details to predict loan approval or rejection.",
        "ä¸­æ–‡": "è¯·è¾“å…¥ç”³è¯·äººä¿¡æ¯ä»¥é¢„æµ‹è´·æ¬¾æ‰¹å‡†æˆ–æ‹’ç»ã€‚",
        "í•œêµ­ì–´": "ëŒ€ì¶œ ìŠ¹ì¸ ë˜ëŠ” ê±°ì ˆì„ ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ ì‹ ì²­ì ì„¸ë¶€ ì •ë³´ë¥¼ ì…ë ¥í•˜ì„¸ìš”.",
        "à¤¹à¤¿à¤‚à¤¦à¥€": "à¤‹à¤£ à¤¸à¥à¤µà¥€à¤•à¥ƒà¤¤à¤¿ à¤¯à¤¾ à¤…à¤¸à¥à¤µà¥€à¤•à¥ƒà¤¤à¤¿ à¤•à¥€ à¤­à¤µà¤¿à¤·à¥à¤¯à¤µà¤¾à¤£à¥€ à¤•à¤°à¤¨à¥‡ à¤•à¥‡ à¤²à¤¿à¤ à¤†à¤µà¥‡à¤¦à¤• à¤µà¤¿à¤µà¤°à¤£ à¤¦à¤°à¥à¤œ à¤•à¤°à¥‡à¤‚à¥¤"
    },
    "sidebar_details": {
        "English": "Applicant Details",
        "ä¸­æ–‡": "ç”³è¯·äººä¿¡æ¯",
        "í•œêµ­ì–´": "ì‹ ì²­ì ì •ë³´",
        "à¤¹à¤¿à¤‚à¤¦à¥€": "à¤†à¤µà¥‡à¤¦à¤• à¤µà¤¿à¤µà¤°à¤£"
    },
    "predict_button": {
        "English": "Predict Credit Risk",
        "ä¸­æ–‡": "é¢„æµ‹ä¿¡ç”¨é£é™©",
        "í•œêµ­ì–´": "ì‹ ìš© ìœ„í—˜ ì˜ˆì¸¡",
        "à¤¹à¤¿à¤‚à¤¦à¥€": "à¤•à¥à¤°à¥‡à¤¡à¤¿à¤Ÿ à¤œà¥‹à¤–à¤¿à¤® à¤•à¥€ à¤­à¤µà¤¿à¤·à¥à¤¯à¤µà¤¾à¤£à¥€ à¤•à¤°à¥‡à¤‚"
    },
    "loan_decision": {
        "English": "Loan Decision",
        "ä¸­æ–‡": "è´·æ¬¾å†³å®š",
        "í•œêµ­ì–´": "ëŒ€ì¶œ ê²°ì •",
        "à¤¹à¤¿à¤‚à¤¦à¥€": "à¤‹à¤£ à¤¨à¤¿à¤°à¥à¤£à¤¯"
    },
    "approved": {
        "English": "âœ… Approved",
        "ä¸­æ–‡": "âœ… æ‰¹å‡†",
        "í•œêµ­ì–´": "âœ… ìŠ¹ì¸ë¨",
        "à¤¹à¤¿à¤‚à¤¦à¥€": "âœ… à¤¸à¥à¤µà¥€à¤•à¥ƒà¤¤"
    },
    "rejected": {
        "English": "âŒ Rejected",
        "ä¸­æ–‡": "âŒ æ‹’ç»",
        "í•œêµ­ì–´": "âŒ ê±°ì ˆë¨",
        "à¤¹à¤¿à¤‚à¤¦à¥€": "âŒ à¤…à¤¸à¥à¤µà¥€à¤•à¥ƒà¤¤"
    },
    "rejection_reasons": {
        "English": "Reasons for Rejection:",
        "ä¸­æ–‡": "æ‹’ç»åŸå› ï¼š",
        "í•œêµ­ì–´": "ê±°ì ˆ ì‚¬ìœ :",
        "à¤¹à¤¿à¤‚à¤¦à¥€": "à¤…à¤¸à¥à¤µà¥€à¤•à¥ƒà¤¤à¤¿ à¤•à¥‡ à¤•à¤¾à¤°à¤£:"
    },
    "enter_value": {
        "English": "Enter value for",
        "ä¸­æ–‡": "è¯·è¾“å…¥",
        "í•œêµ­ì–´": "ê°’ ì…ë ¥:",
        "à¤¹à¤¿à¤‚à¤¦à¥€": "à¤•à¥‡ à¤²à¤¿à¤ à¤®à¤¾à¤¨ à¤¦à¤°à¥à¤œ à¤•à¤°à¥‡à¤‚"
    },
    # ä»¥ä¸‹ä¸ºé’ˆå¯¹æ‰€æœ‰å˜é‡çš„é€šç”¨åŸå› æç¤ºæ¨¡æ¿
    "reason_positive": {
        "English": "{} contributes positively with a value of {:.2f}, increasing the likelihood of approval.",
        "ä¸­æ–‡": "{} å¯¹æ‰¹å‡†æœ‰æ­£é¢å½±å“ï¼ˆè´¡çŒ®å€¼ï¼š{:.2f}ï¼‰ï¼Œæœ‰åŠ©äºè´·æ¬¾æ‰¹å‡†ã€‚",
        "í•œêµ­ì–´": "{} ëŠ” ê¸ì •ì ìœ¼ë¡œ ê¸°ì—¬í•©ë‹ˆë‹¤ (ê¸°ì—¬ê°’: {:.2f}), ìŠ¹ì¸ ê°€ëŠ¥ì„±ì„ ë†’ì…ë‹ˆë‹¤.",
        "à¤¹à¤¿à¤‚à¤¦à¥€": "{} à¤¸à¤•à¤¾à¤°à¤¾à¤¤à¥à¤®à¤• à¤°à¥‚à¤ª à¤¸à¥‡ à¤¯à¥‹à¤—à¤¦à¤¾à¤¨ à¤¦à¥‡à¤¤à¤¾ à¤¹à¥ˆ (à¤¯à¥‹à¤—à¤¦à¤¾à¤¨: {:.2f}), à¤¸à¥à¤µà¥€à¤•à¥ƒà¤¤à¤¿ à¤•à¥€ à¤¸à¤‚à¤­à¤¾à¤µà¤¨à¤¾ à¤¬à¤¢à¤¼à¤¾à¤¤à¤¾ à¤¹à¥ˆà¥¤"
    },
    "reason_negative": {
        "English": "{} contributes negatively with a value of {:.2f}, reducing the likelihood of approval.",
        "ä¸­æ–‡": "{} å¯¹æ‰¹å‡†æœ‰è´Ÿé¢å½±å“ï¼ˆè´¡çŒ®å€¼ï¼š{:.2f}ï¼‰ï¼Œé™ä½è´·æ¬¾æ‰¹å‡†çš„å¯èƒ½æ€§ã€‚",
        "í•œêµ­ì–´": "{} ëŠ” ë¶€ì •ì ìœ¼ë¡œ ê¸°ì—¬í•©ë‹ˆë‹¤ (ê¸°ì—¬ê°’: {:.2f}), ìŠ¹ì¸ ê°€ëŠ¥ì„±ì„ ë‚®ì¶¥ë‹ˆë‹¤.",
        "à¤¹à¤¿à¤‚à¤¦à¥€": "{} à¤¨à¤•à¤¾à¤°à¤¾à¤¤à¥à¤®à¤• à¤°à¥‚à¤ª à¤¸à¥‡ à¤¯à¥‹à¤—à¤¦à¤¾à¤¨ à¤¦à¥‡à¤¤à¤¾ à¤¹à¥ˆ (à¤¯à¥‹à¤—à¤¦à¤¾à¤¨: {:.2f}), à¤¸à¥à¤µà¥€à¤•à¥ƒà¤¤à¤¿ à¤•à¥€ à¤¸à¤‚à¤­à¤¾à¤µà¤¨à¤¾ à¤•à¤® à¤•à¤°à¤¤à¤¾ à¤¹à¥ˆà¥¤"
    },
    "reason_neutral": {
        "English": "{} has no significant influence (contribution: {:.2f}).",
        "ä¸­æ–‡": "{} å¯¹æ‰¹å‡†æ²¡æœ‰æ˜¾è‘—å½±å“ï¼ˆè´¡çŒ®å€¼ï¼š{:.2f}ï¼‰ã€‚",
        "í•œêµ­ì–´": "{} ëŠ” ìœ ì˜ë¯¸í•œ ì˜í–¥ì„ ë¯¸ì¹˜ì§€ ì•ŠìŠµë‹ˆë‹¤ (ê¸°ì—¬ê°’: {:.2f}).",
        "à¤¹à¤¿à¤‚à¤¦à¥€": "{} à¤•à¤¾ à¤•à¥‹à¤ˆ à¤®à¤¹à¤¤à¥à¤µà¤ªà¥‚à¤°à¥à¤£ à¤ªà¥à¤°à¤­à¤¾à¤µ à¤¨à¤¹à¥€à¤‚ à¤¹à¥ˆ (à¤¯à¥‹à¤—à¤¦à¤¾à¤¨: {:.2f})à¥¤"
    }
}

# è¯­è¨€é€‰æ‹©
language = st.sidebar.selectbox("Language / è¯­è¨€ / ì–¸ì–´ / à¤­à¤¾à¤·à¤¾", 
                                options=["English", "ä¸­æ–‡", "í•œêµ­ì–´", "à¤¹à¤¿à¤‚à¤¦à¥€"])

# åº”ç”¨æ ‡é¢˜å’Œæè¿°
st.title(translations["app_title"][language])
st.write(translations["app_description"][language])

# æ‰‹åŠ¨è¾“å…¥å„é¡¹ç”³è¯·äººå‚æ•°ï¼ˆä½¿ç”¨ number_input ç»„ä»¶ï¼‰
st.sidebar.header(translations["sidebar_details"][language])
external_risk = st.sidebar.number_input(
    label=f"{translations['enter_value'][language]} External Risk Estimate",
    min_value=0, max_value=100, value=50, step=1
)
msince_oldest_trade = st.sidebar.number_input(
    label=f"{translations['enter_value'][language]} Months Since Oldest Trade",
    min_value=0, max_value=500, value=100, step=1
)
msince_most_recent_trade = st.sidebar.number_input(
    label=f"{translations['enter_value'][language]} Months Since Most Recent Trade",
    min_value=0, max_value=100, value=10, step=1
)
average_m_in_file = st.sidebar.number_input(
    label=f"{translations['enter_value'][language]} Average Months in File",
    min_value=0, max_value=200, value=50, step=1
)
num_satisfactory_trades = st.sidebar.number_input(
    label=f"{translations['enter_value'][language]} Number of Satisfactory Trades",
    min_value=0, max_value=50, value=15, step=1
)
num_trades_60_ever = st.sidebar.number_input(
    label=f"{translations['enter_value'][language]} Num Trades 60+ Ever",
    min_value=0, max_value=20, value=5, step=1
)
num_trades_90_ever = st.sidebar.number_input(
    label=f"{translations['enter_value'][language]} Num Trades 90+ Ever",
    min_value=0, max_value=20, value=5, step=1
)
percent_trades_never_delq = st.sidebar.number_input(
    label=f"{translations['enter_value'][language]} Percent of Trades Never Delinquent",
    min_value=0, max_value=100, value=80, step=1
)
msince_most_recent_delq = st.sidebar.number_input(
    label=f"{translations['enter_value'][language]} Months Since Most Recent Delinquency",
    min_value=0, max_value=100, value=10, step=1
)
max_delq_12m = st.sidebar.number_input(
    label=f"{translations['enter_value'][language]} Max Delinquency in Last 12M",
    min_value=0, max_value=10, value=5, step=1
)
max_delq_ever = st.sidebar.number_input(
    label=f"{translations['enter_value'][language]} Max Delinquency Ever",
    min_value=0, max_value=10, value=5, step=1
)
num_total_trades = st.sidebar.number_input(
    label=f"{translations['enter_value'][language]} Number of Total Trades",
    min_value=0, max_value=50, value=10, step=1
)
num_trades_open_12m = st.sidebar.number_input(
    label=f"{translations['enter_value'][language]} Number of Trades Open in Last 12M",
    min_value=0, max_value=20, value=5, step=1
)
percent_install_trades = st.sidebar.number_input(
    label=f"{translations['enter_value'][language]} Percent Installment Trades",
    min_value=0, max_value=100, value=50, step=1
)
msince_most_recent_inq = st.sidebar.number_input(
    label=f"{translations['enter_value'][language]} Months Since Most Recent Inquiry (excl 7 days)",
    min_value=0, max_value=100, value=10, step=1
)
num_inq_last_6m = st.sidebar.number_input(
    label=f"{translations['enter_value'][language]} Num Inquiries Last 6M",
    min_value=0, max_value=20, value=2, step=1
)
num_inq_last_6m_excl7 = st.sidebar.number_input(
    label=f"{translations['enter_value'][language]} Num Inquiries Last 6M (excl 7 days)",
    min_value=0, max_value=20, value=2, step=1
)
net_fraction_revolving_burden = st.sidebar.number_input(
    label=f"{translations['enter_value'][language]} Net Fraction Revolving Burden",
    min_value=0, max_value=100, value=50, step=1
)
net_fraction_install_burden = st.sidebar.number_input(
    label=f"{translations['enter_value'][language]} Net Fraction Install Burden",
    min_value=0, max_value=100, value=50, step=1
)
num_revolving_trades_balance = st.sidebar.number_input(
    label=f"{translations['enter_value'][language]} Num Revolving Trades With Balance",
    min_value=0, max_value=20, value=5, step=1
)
num_install_trades_balance = st.sidebar.number_input(
    label=f"{translations['enter_value'][language]} Num Install Trades With Balance",
    min_value=0, max_value=20, value=5, step=1
)
num_bank_natl_trades_high_util = st.sidebar.number_input(
    label=f"{translations['enter_value'][language]} Num Bank/National Trades High Utilization",
    min_value=0, max_value=20, value=5, step=1
)
percent_trades_balance = st.sidebar.number_input(
    label=f"{translations['enter_value'][language]} Percent Trades With Balance",
    min_value=0, max_value=100, value=50, step=1
)

# =============================================================================
# å®šä¹‰åŸºäº Logistic Regression æ¨¡å‹è´¡çŒ®è®¡ç®—çš„æ‹’ç»åŸå› åé¦ˆå‡½æ•°
# å¯¹æ¯ä¸ªå˜é‡éƒ½æä¾›åŸå› è¯´æ˜
# =============================================================================
def get_logistic_rejection_reasons(input_data, lang):
    # å¯¹è¾“å…¥æ•°æ®è¿›è¡Œæ ‡å‡†åŒ–
    input_scaled = scaler.transform(input_data)
    # è®¡ç®—å„ç‰¹å¾è´¡çŒ®ï¼šè´¡çŒ® = æ ‡å‡†åŒ–å€¼ * æ¨¡å‹ç³»æ•°
    contributions = input_scaled[0] * logistic_regression_model.coef_[0]
    # æ„å»º {ç‰¹å¾å: è´¡çŒ®å€¼} å­—å…¸
    feature_contribs = {feature: contrib for feature, contrib in zip(scaler.feature_names_in_, contributions)}
    
    reasons = []
    # éå†æ‰€æœ‰å˜é‡ï¼Œç”Ÿæˆå¯¹åº”åŸå› è¯´æ˜
    for feature, contrib in feature_contribs.items():
        # æ ¹æ®è´¡çŒ®å€¼åˆ¤æ–­è¯´æ˜ç±»å‹
        if abs(contrib) < 0.05:
            reason = translations["reason_neutral"][lang].format(feature, contrib)
        elif contrib < 0:
            reason = translations["reason_negative"][lang].format(feature, contrib)
        else:
            reason = translations["reason_positive"][lang].format(feature, contrib)
        reasons.append(reason)
    return reasons

# =============================================================================
# é¢„æµ‹å‡½æ•°ï¼ˆä»…ä½¿ç”¨ Logistic Regression æ¨¡å‹ï¼‰
# =============================================================================
def make_prediction():
    st.session_state["button_clicked"] = True  # æ›´æ–°çŠ¶æ€

    # æ„é€ è¾“å…¥æ•°æ®ï¼Œå­—æ®µåç§°é¡»ä¸è®­ç»ƒæ—¶ä¸€è‡´
    input_data = pd.DataFrame({
        "ExternalRiskEstimate": [external_risk],
        "MSinceOldestTradeOpen": [msince_oldest_trade],
        "MSinceMostRecentTradeOpen": [msince_most_recent_trade],
        "AverageMInFile": [average_m_in_file],
        "NumSatisfactoryTrades": [num_satisfactory_trades],
        "NumTrades60Ever2DerogPubRec": [num_trades_60_ever],
        "NumTrades90Ever2DerogPubRec": [num_trades_90_ever],
        "PercentTradesNeverDelq": [percent_trades_never_delq],
        "MSinceMostRecentDelq": [msince_most_recent_delq],
        "MaxDelq2PublicRecLast12M": [max_delq_12m],
        "MaxDelqEver": [max_delq_ever],
        "NumTotalTrades": [num_total_trades],
        "NumTradesOpeninLast12M": [num_trades_open_12m],
        "PercentInstallTrades": [percent_install_trades],
        "MSinceMostRecentInqexcl7days": [msince_most_recent_inq],
        "NumInqLast6M": [num_inq_last_6m],
        "NumInqLast6Mexcl7days": [num_inq_last_6m_excl7],
        "NetFractionRevolvingBurden": [net_fraction_revolving_burden],
        "NetFractionInstallBurden": [net_fraction_install_burden],
        "NumRevolvingTradesWBalance": [num_revolving_trades_balance],
        "NumInstallTradesWBalance": [num_install_trades_balance],
        "NumBank2NatlTradesWHighUtilization": [num_bank_natl_trades_high_util],
        "PercentTradesWBalance": [percent_trades_balance]
    })
    
    # ç¡®ä¿ç‰¹å¾é¡ºåºä¸è®­ç»ƒæ—¶ä¸€è‡´
    input_data = input_data[scaler.feature_names_in_]
    
    # å¯¹è¾“å…¥æ•°æ®è¿›è¡Œæ ‡å‡†åŒ–ï¼ˆå› ä¸ºæ¨¡å‹è®­ç»ƒæ—¶ä½¿ç”¨äº†æ ‡å‡†åŒ–æ•°æ®ï¼‰
    input_scaled = scaler.transform(input_data)
    
    # è¿›è¡Œé¢„æµ‹
    prediction = logistic_regression_model.predict(input_scaled)[0]
    st.session_state["prediction"] = prediction
    
    # å¦‚æœé¢„æµ‹ä¸ºæ‹’ç»ï¼ˆ0ï¼‰ï¼Œè®¡ç®—æ¯ä¸ªå˜é‡çš„è´¡çŒ®å¹¶ç»™å‡ºè¯¦ç»†åŸå› 
    if prediction == 0:
        reasons = get_logistic_rejection_reasons(input_data, language)
        st.session_state["reasons"] = reasons
    else:
        st.session_state["reasons"] = []

# =============================================================================
# åˆå§‹åŒ–çŠ¶æ€å¹¶å±•ç¤ºé¢„æµ‹æŒ‰é’®ä¸ç»“æœ
# =============================================================================
st.session_state.setdefault("prediction", None)
st.session_state.setdefault("button_clicked", False)
st.session_state.setdefault("reasons", [])

if st.button(translations["predict_button"][language]):
    make_prediction()

if st.session_state["button_clicked"]:
    if st.session_state["prediction"] is not None:
        if st.session_state["prediction"] == 1:
            result = translations["approved"][language]
            st.write(f"### {translations['loan_decision'][language]}: {result}")
        else:
            result = translations["rejected"][language]
            st.write(f"### {translations['loan_decision'][language]}: {result}")
            if st.session_state["reasons"]:
                st.write(f"**{translations['rejection_reasons'][language]}**")
                for reason in st.session_state["reasons"]:
                    st.write(f"- {reason}")
            else:
                st.write("No specific rejection reasons provided.")
    else:
        st.warning("âš ï¸ " + translations["predict_button"][language] + " to make a prediction.")